{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1d04ae",
   "metadata": {},
   "source": [
    "# Preprocessing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234015ca",
   "metadata": {},
   "source": [
    "### RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1c470",
   "metadata": {},
   "source": [
    "RegEx is especially useful for cleaning out unwanted punctuation marks, captialized letters, special characters etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a498ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524233b9",
   "metadata": {},
   "source": [
    "Eg. Replacing Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162660d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harper is the goodest girl.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string='Harper is a good girl.'\n",
    "#'.' represents any character, while * represents zero or more occurences\n",
    "#in this case, '..g.*d' will match with 'a good'\n",
    "#re.sub replaces this with 'the goodest'\n",
    "re.sub('..g.*d','the goodest',string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2dc87",
   "metadata": {},
   "source": [
    "Using RegEx to remove special chars and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c016470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " One ring to rule them all One ring to find them One ring to bring them all and in the darkness bind them \n"
     ]
    }
   ],
   "source": [
    "string='''\n",
    "One ring to rule them all,\n",
    "One ring to find them, One ring to bring them all,\n",
    "and in the darkness, bind them.\n",
    "'''\n",
    "\n",
    "string=re.sub('(<.*?>)', ' ', string)\n",
    "string=re.sub('[,\\.!?:()\"]', '', string)\n",
    "string=re.sub('[^a-zA-Z\"]',' ',string)\n",
    "\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae816fce",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669faaa",
   "metadata": {},
   "source": [
    "Tokenizing a string into individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5d66c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'ring', 'to', 'rule', 'them', 'all', 'One', 'ring', 'to', 'find', 'them', 'One', 'ring', 'to', 'bring', 'them', 'all', 'and', 'in', 'the', 'darkness', 'bind', 'them']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words=word_tokenize(string)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ad494",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf5518a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\liuru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d82a122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " from the tip of hi wand burst the silver doe . she land on the offic floor , bound onc across the offic , and soar out of the window . dumbledor watch her fli away , and as her silveri glow fade he turn back to snape , and hi eye were full of tear . “ after all thi time ? ” “ alway , ” said snape .\n"
     ]
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "\n",
    "string='''\n",
    "From the tip of his wand burst the silver doe. She landed on the office floor, bounded once across the office, and soared out of the window. Dumbledore watched her fly away, and as her silvery glow faded he turned back to Snape, and his eyes were full of tears.\n",
    "“After all this time?”\n",
    "“Always,” said Snape.\n",
    "'''\n",
    "\n",
    "words=word_tokenize(string)\n",
    "stemmed_string = reduce(lambda x, y: x +\" \"+ps.stem(y), words, \"\")\n",
    "print(stemmed_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8142320",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a1a12",
   "metadata": {},
   "source": [
    "For the lemmatizer to work as intended, we need to give th lemmatizer the context of each word. This is achieved through POS tagging, which will be covered in greatee detail next week. The default POS tagger assumes all words to be nouns if no context is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca64c4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\liuru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\liuru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c86b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd408bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('From', None), ('the', None), ('tip', 'n'), ('of', None), ('his', None), ('wand', 'n'), ('burst', 'v'), ('the', None), ('silver', 'n'), ('doe', 'n'), ('.', None), ('She', None), ('landed', 'v'), ('on', None), ('the', None), ('office', 'n'), ('floor', 'n'), (',', None), ('bounded', 'v'), ('once', 'r'), ('across', None), ('the', None), ('office', 'n'), (',', None), ('and', None), ('soared', 'v'), ('out', None), ('of', None), ('the', None), ('window', 'n'), ('.', None), ('Dumbledore', 'n'), ('watched', 'v'), ('her', None), ('fly', 'n'), ('away', 'r'), (',', None), ('and', None), ('as', None), ('her', None), ('silvery', 'n'), ('glow', 'n'), ('faded', 'v'), ('he', None), ('turned', 'v'), ('back', 'r'), ('to', None), ('Snape', 'n'), (',', None), ('and', None), ('his', None), ('eyes', 'n'), ('were', 'v'), ('full', 'a'), ('of', None), ('tears', 'n'), ('.', None), ('“', 'n'), ('After', None), ('all', None), ('this', None), ('time', 'n'), ('?', None), ('”', 'a'), ('“', 'n'), ('Always', 'n'), (',', None), ('”', 'n'), ('said', 'v'), ('Snape', 'n'), ('.', None), ('”', 'n')]\n"
     ]
    }
   ],
   "source": [
    "string = '''\n",
    "From the tip of his wand burst the silver doe. \n",
    "She landed on the office floor, bounded once across the office, and soared out of the window. \n",
    "Dumbledore watched her fly away, and as her silvery glow faded he turned back to Snape, and his eyes were full of tears.\n",
    "“After all this time?”\n",
    "“Always,” said Snape.”\n",
    "'''\n",
    "pos_tagged = nltk.pos_tag(nltk.word_tokenize(string))\n",
    "\n",
    "wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tagged))\n",
    "print(wordnet_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a076316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the tip of his wand burst the silver doe . She land on the office floor , bound once across the office , and soar out of the window . Dumbledore watch her fly away , and as her silvery glow fade he turn back to Snape , and his eye be full of tear . “ After all this time ? ” “ Always , ” say Snape . ”\n"
     ]
    }
   ],
   "source": [
    "lemmatized_sentence = []\n",
    "\n",
    "for word, tag in wordnet_tagged:\n",
    "    if tag is None:\n",
    "        lemmatized_sentence.append(word)\n",
    "    else:       \n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    " \n",
    "print(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0676caaf",
   "metadata": {},
   "source": [
    "### Preprocessing for BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5e47839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'gon', 'na', 'run', 'around', 'desert', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "text = '''\n",
    "Never gonna run around and desert you.\n",
    "'''\n",
    "\n",
    "dataset= nltk.word_tokenize(text)\n",
    "for i in range(len(dataset)):\n",
    "    dataset[i] = dataset[i].lower()\n",
    "    dataset[i] = re.sub(r'/W', ' ', dataset[i])\n",
    "    dataset[i] = re.sub(r'/s+', ' ', dataset[i])\n",
    "filtered_sentence = [w for w in dataset if not w.lower() in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b8a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensforflow_base",
   "language": "python",
   "name": "tensforflow_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
